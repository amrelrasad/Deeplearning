{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Classification Using Transfer Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook provides general framework for image classification using transfer learning. The user should input the image folder path and choose the model parameters. The user should choose the network among the pre-saved networks in Pytorch. Also the user should change MLP classifier part to be consistent with the labels in the image folder.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Imports and data loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms, models\n",
    "from sklearn.metrics import classification_report,accuracy_score,confusion_matrix\n",
    "import matplotlib.pyplot as plt                        \n",
    "%matplotlib inline\n",
    "import os\n",
    "import datetime\n",
    "import time\n",
    "from PIL import ImageFile\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create data loaders:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load data\n",
    "dataPath=\"your image folder path\"\n",
    "#define data transforms\n",
    "train_transforms = transforms.Compose([transforms.RandomRotation(30),\n",
    "                                       transforms.RandomResizedCrop(224),\n",
    "                                       transforms.RandomHorizontalFlip(),\n",
    "                                       transforms.ToTensor(),\n",
    "                                       transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                                                            [0.229, 0.224, 0.225])])\n",
    "\n",
    "test_transforms = transforms.Compose([transforms.Resize(255),\n",
    "                                      transforms.CenterCrop(224),\n",
    "                                      transforms.ToTensor(),\n",
    "                                      transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                                                           [0.229, 0.224, 0.225])])\n",
    "valid_transforms = transforms.Compose([transforms.Resize(255),\n",
    "                                      transforms.CenterCrop(224),\n",
    "                                      transforms.ToTensor(),\n",
    "                                      transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                                                           [0.229, 0.224, 0.225])])\n",
    "\n",
    "# data\n",
    "train_data = datasets.ImageFolder(dataPath + '/train', transform=train_transforms)\n",
    "valid_data = datasets.ImageFolder(dataPath+ '/valid', transform=valid_transforms)\n",
    "test_data = datasets.ImageFolder(dataPath+ '/test', transform=test_transforms)\n",
    "\n",
    "# loaders\n",
    "trainloader = torch.utils.data.DataLoader(train_data, batch_size=28, shuffle=True)\n",
    "validloader = torch.utils.data.DataLoader(valid_data, batch_size=64)\n",
    "testloader = torch.utils.data.DataLoader(test_data, batch_size=64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Model Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model parameters include: network index, pre-trained network, re-train existing saved model, and learning rate. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model parameters\n",
    "# do not edit this part\n",
    "net_dic={0:\"alexnet\",\n",
    "        1:\"vgg11\",\n",
    "        2:\"vgg13\",\n",
    "        3:\"vgg16\",\n",
    "        4:\"vgg19\",\n",
    "        5:\"vgg11_bn\",\n",
    "        6:\"vgg13_bn\",\n",
    "        7:\"vgg16_bn\",\n",
    "        8:\"vgg19_bn\",\n",
    "        9:\"resnet18\",\n",
    "        10:\"resnet34\",\n",
    "        11:\"resnet50\",\n",
    "        12:\"resnet101\",\n",
    "        13:\"resnet152\",\n",
    "        14:\"densenet121\",\n",
    "        15:\"densenet169\",\n",
    "        16:\"densenet201\",\n",
    "        17:\"densenet161\",\n",
    "        18:\"inception_v3\",\n",
    "}\n",
    "FC=[9216,25088,25088,25088,25088,25088,25088,25088,25088,512,512,2048,2048,2048,1024,1664,1920,2208,2048]\n",
    "# you can change settins in this part\n",
    "net_index=11 # index of network to be choosen\n",
    "selected_net=net_dic[net_index]\n",
    "output_classes=len(train_data.class_to_idx)\n",
    "full_train=True # full train network or part of it\n",
    "net_pretrained=False # load pre-trained network or not\n",
    "retrain=True # re-train saved model\n",
    "learning_rate=0.00000001\n",
    "# enter model path and file name where you want to load or save your new model\n",
    "model_path=\"Your model full path and name\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Functions Definitions "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, the functions needed to train and test model are defined."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Testing Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#testing model\n",
    "# returns test accuracy, loss, number of correctly labeled predictions\n",
    "# input: data loader, model, loss function, device\n",
    "def test_model( model, loader,criterion, device):\n",
    "    test_loss = 0.0\n",
    "    test_count=0.0\n",
    "    test_size=0.0\n",
    "    test_accuracy = 0.0\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in loader:\n",
    "            test_size+=len(labels)\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            logps = model.forward(inputs)\n",
    "            batch_loss = criterion(logps, labels)\n",
    "            test_loss += batch_loss.item()\n",
    "            # Calculate accuracy\n",
    "            ps = torch.exp(logps)\n",
    "            top_p, top_class = ps.topk(1, dim=1)\n",
    "            equals = top_class == labels.view(*top_class.shape)\n",
    "            test_count+=torch.sum(equals.type(torch.FloatTensor))\n",
    "        test_accuracy=test_count/test_size\n",
    "        test_loss=test_loss/len(loader)\n",
    "    return test_accuracy,test_loss,test_count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Testing and Reporting Model Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#testing and reporting model\n",
    "# returns test accuracy, and number of correctly labeled predictions,classification report, confusion matrix\n",
    "# input: data loader, model, loss, device\n",
    "def test_report(model, loader,device):\n",
    "    test_count=0.0\n",
    "    test_size=0\n",
    "    test_accuracy = 0.0\n",
    "    predictions=[]\n",
    "    true_labels=[]\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for inputs,labels in loader:\n",
    "            test_size+=len(inputs)\n",
    "            inputs=inputs.to(device)\n",
    "            labels=labels.to(device)\n",
    "            Z = model.forward(inputs)\n",
    "            ps = torch.exp(Z)\n",
    "            top_p, top_class = ps.topk(1, dim=1)\n",
    "            equals = top_class == labels.view(*top_class.shape)\n",
    "            test_count+=torch.sum(equals.type(torch.FloatTensor))\n",
    "            true_labels+=(labels.squeeze().tolist())\n",
    "            predictions+=(top_class.squeeze().tolist())\n",
    "        test_accuracy=test_count/test_size\n",
    "        report=classification_report(true_labels, predictions)\n",
    "        conf_matrix=confusion_matrix(true_labels,predictions)   \n",
    "    return test_accuracy,test_count,report,conf_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Training Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training model\n",
    "# imput: number of epochs,model,  train loader, validation loader, ptimizer, loss function, \n",
    "# model path, current maximum corretly labeled predictions in validation loader\n",
    "# returns model, new maximum corretly labeled predictions in validation loader\n",
    "def train_model(model,epochs, trainloader,validloader, optimizer, criterion, device, model_path_name,valid_count_max):\n",
    "\n",
    "    start=time.time()\n",
    "    print (datetime.datetime.now())\n",
    "    steps = 0\n",
    "    print_every = 20\n",
    "    #test_acc_max = 0.8*len(testloader) # track change in validation loss\n",
    "    for epoch in range(epochs):\n",
    "        step=0\n",
    "        train_loss = 0.0\n",
    "        model.train()\n",
    "        for inputs, labels in trainloader:\n",
    "            step += 1\n",
    "            if(step%print_every==0):\n",
    "                print(f\"Epoch {epoch+1}/{epochs}..step {step}/{len(trainloader)}..\"\n",
    "                      f\"time so far {(time.time()-start)/60:.3f} mins\")\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            logps = model.forward(inputs)\n",
    "            loss = criterion(logps, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item()\n",
    "            # Calculate accuracy\n",
    "            ps = torch.exp(logps)\n",
    "            top_p, top_class = ps.topk(1, dim=1)\n",
    "            equals = top_class == labels.view(*top_class.shape)\n",
    "        train_loss=train_loss/len(trainloader)\n",
    "        valid_accuracy, valid_loss,valid_count=test_model(model,validloader,criterion,device)\n",
    "        print (datetime.datetime.now())\n",
    "        print(f\"Epoch {epoch+1}/{epochs}.. \"\n",
    "              f\"Train loss: {train_loss:.3f}.. \"\n",
    "              f\"Valid loss: {valid_loss:.3f}.. \"\n",
    "              f\"Valid accuracy: {valid_accuracy:.5f}..\"\n",
    "              f\"Time Elspased so far: {time.time()-start:.3f} seconds\")\n",
    "        train_loss = 0\n",
    "        train_accuracy=0\n",
    "        if valid_count>valid_count_max:\n",
    "            print(f\"*************New Model Saved with correct predictions of:{valid_count:.5f}***************\")\n",
    "            torch.save(model, model_path_name)\n",
    "            valid_count_max= valid_count\n",
    "    return model,valid_count_max"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Model Creation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In his section, the neural network is created by either loaded from models library or loaded from pre-saved model file. The FC classifier needs to be changed to fit the problem requirements. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model instainstiation\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "if(retrain):\n",
    "    model = torch.load(model_path)\n",
    "else:\n",
    "    model=eval(\"models.\"+selected_net+\"(pretrained=net_pretrained)\")\n",
    "    torch.save(model, model_path)\n",
    "    if(not full_train):\n",
    "        for par in  model.parameters():\n",
    "            param.requires_grad=False\n",
    "    #change FC classifier\n",
    "    # You may change this part according to the the problem requirments\n",
    "    model.fc = nn.Sequential(nn.Linear(FC[net_index], 1024),\n",
    "                                     nn.Tanh(),\n",
    "                                     nn.Linear(1024, 256),\n",
    "                                     nn.Tanh(),\n",
    "                                     #nn.Dropout(0.2), #optional\n",
    "                                     nn.Linear(256, output_classes),\n",
    "                                     nn.LogSoftmax(dim=1)) \n",
    "    \n",
    "\n",
    "criterion = nn.NLLLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "model.to(device);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 Model Current  Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test model intially over validation set\n",
    "valid_acc_max,valid_loss,valid_count_max=test_model(model,validloader,criterion,device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model,model_path)\n",
    "valid_acc_max,valid_loss,valid_count_max"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.2 Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train model\n",
    "model,valid_count_max = train_model(model,2, trainloader,validloader, optimizer,criterion,device,model_path,valid_count_max) \n",
    "print(valid_count_max)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Model Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load best model\n",
    "model = torch.load(model_path)\n",
    "model.to(device)\n",
    "acc,_,report,conf_matrix=test_report(model,testloader,device)\n",
    "print(\"Test Data Set Accuracy = \",acc)\n",
    "print(\"Calssification Report\")\n",
    "print(\"*\"*50)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#view Confusion Matrix\n",
    "df=pd.DataFrame(conf_matrix)\n",
    "pd.set_option('display.max_columns', output_classes,'display.max_rows',output_classes)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader_dic={\"train\":trainloader,\"valid\":validloader,\"test\":testloader}\n",
    "#loader_dic={\"valid\":validloader,\"test\":testloader}\n",
    "for i in loader_dic:\n",
    "    loader=loader_dic[i]\n",
    "    print(i+\" data set\")\n",
    "    test_report_model(model,loader,device)\n",
    "    print(\"*\"*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
