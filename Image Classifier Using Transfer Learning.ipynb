{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms, models\n",
    "from sklearn.metrics import classification_report\n",
    "import matplotlib.pyplot as plt                        \n",
    "%matplotlib inline\n",
    "import os\n",
    "import datetime\n",
    "import time\n",
    "from PIL import ImageFile\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load data\n",
    "dataPath=\"/media/amrelrasad/LENOVO/Backup_Linux/Documents/Pytorch_Udacity/deep-learning-v2-pytorch/project-dog-classification/dogImages\"\n",
    "#define data transforms\n",
    "train_transforms = transforms.Compose([transforms.RandomRotation(30),\n",
    "                                       transforms.RandomResizedCrop(224),\n",
    "                                       transforms.RandomHorizontalFlip(),\n",
    "                                       transforms.ToTensor(),\n",
    "                                       transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                                                            [0.229, 0.224, 0.225])])\n",
    "\n",
    "test_transforms = transforms.Compose([transforms.Resize(255),\n",
    "                                      transforms.CenterCrop(224),\n",
    "                                      transforms.ToTensor(),\n",
    "                                      transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                                                           [0.229, 0.224, 0.225])])\n",
    "valid_transforms = transforms.Compose([transforms.Resize(255),\n",
    "                                      transforms.CenterCrop(224),\n",
    "                                      transforms.ToTensor(),\n",
    "                                      transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                                                           [0.229, 0.224, 0.225])])\n",
    "\n",
    "# data\n",
    "train_data = datasets.ImageFolder(dataPath + '/train', transform=train_transforms)\n",
    "valid_data = datasets.ImageFolder(dataPath+ '/valid', transform=valid_transforms)\n",
    "test_data = datasets.ImageFolder(dataPath+ '/test', transform=test_transforms)\n",
    "\n",
    "# loaders\n",
    "trainloader = torch.utils.data.DataLoader(train_data, batch_size=32, shuffle=True)\n",
    "validloader = torch.utils.data.DataLoader(valid_data, batch_size=64)\n",
    "testloader = torch.utils.data.DataLoader(test_data, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model parameters\n",
    "net_dic={0:\"alexnet\",\n",
    "        1:\"vgg11\",\n",
    "        2:\"vgg13\",\n",
    "        3:\"vgg16\",\n",
    "        4:\"vgg19\",\n",
    "        5:\"vgg11_bn\",\n",
    "        6:\"vgg13_bn\",\n",
    "        7:\"vgg16_bn\",\n",
    "        8:\"vgg19_bn\",\n",
    "        9:\"resnet18\",\n",
    "        10:\"resnet34\",\n",
    "        11:\"resnet50\",\n",
    "        12:\"resnet101\",\n",
    "        13:\"resnet152\",\n",
    "        14:\"densenet121\",\n",
    "        15:\"densenet169\",\n",
    "        16:\"densenet201\",\n",
    "        17:\"densenet161\",\n",
    "        18:\"inception_v3\",\n",
    "}\n",
    "FC=[9216,25088,25088,25088,25088,25088,25088,25088,25088,512,512,2048,2048,2048,1024,1664,1920,2208,2048]\n",
    "net_index=11\n",
    "selected_net=net_dic[net_index]\n",
    "output_classes=len(train_data.class_to_idx)\n",
    "full_train=True\n",
    "net_pretrained=True\n",
    "retrain=True\n",
    "learning_rate=0.00000001\n",
    "# enter model path and file name where you want to load or save your new model\n",
    "model_path=\"image_model.pth\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(output_classes)\n",
    "print(selected_net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(loader, model,criterion, device):\n",
    "    test_loss = 0.0\n",
    "    test_count=0.0\n",
    "    test_size=0.0\n",
    "    test_accuracy = 0.0\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in loader:\n",
    "            test_size+=len(labels)\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            logps = model.forward(inputs)\n",
    "            batch_loss = criterion(logps, labels)\n",
    "            test_loss += batch_loss.item()\n",
    "            # Calculate accuracy\n",
    "            ps = torch.exp(logps)\n",
    "            top_p, top_class = ps.topk(1, dim=1)\n",
    "            equals = top_class == labels.view(*top_class.shape)\n",
    "            test_count+=torch.sum(equals.type(torch.FloatTensor))\n",
    "        test_accuracy=test_count/test_size\n",
    "        test_loss=test_loss/len(loader)\n",
    "    return test_accuracy,test_loss,test_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_report(model, loader,device):\n",
    "    test_count=0.0\n",
    "    test_size=0\n",
    "    test_accuracy = 0.0\n",
    "    predictions=[]\n",
    "    true_labels=[]\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for inputs,labels in loader:\n",
    "            test_size+=len(inputs)\n",
    "            inputs=inputs.to(device)\n",
    "            labels=labels.to(device)\n",
    "            Z = model.forward(inputs)\n",
    "            ps = torch.exp(Z)\n",
    "            top_p, top_class = ps.topk(1, dim=1)\n",
    "            equals = top_class == labels.view(*top_class.shape)\n",
    "            test_count+=torch.sum(equals.type(torch.FloatTensor))\n",
    "            true_labels+=(labels.squeeze().tolist())\n",
    "            predictions+=(top_class.squeeze().tolist())\n",
    "        test_accuracy=test_count/test_size\n",
    "        print(classification_report(true_labels, predictions))\n",
    "            \n",
    "    return test_accuracy,test_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epochs, trainloader,validloader, model, optimizer, criterion, device, model_path_name,valid_count_max):\n",
    "\n",
    "    start=time.time()\n",
    "    print (datetime.datetime.now())\n",
    "    steps = 0\n",
    "\n",
    "    print_every = 200\n",
    "    #test_acc_max = 0.8*len(testloader) # track change in validation loss\n",
    "    for epoch in range(epochs):\n",
    "        step=0\n",
    "        train_loss = 0.0\n",
    "        model.train()\n",
    "        for inputs, labels in trainloader:\n",
    "            step += 1\n",
    "            if(step%print_every==0):\n",
    "                print(f\"Epoch {epoch+1}/{epochs}..step {step}/{len(trainloader)}..\"\n",
    "                      f\"time so far {(time.time()-start)/60:.3f} mins\")\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            logps = model.forward(inputs)\n",
    "            loss = criterion(logps, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item()\n",
    "            # Calculate accuracy\n",
    "            ps = torch.exp(logps)\n",
    "            top_p, top_class = ps.topk(1, dim=1)\n",
    "            equals = top_class == labels.view(*top_class.shape)\n",
    "        train_loss=train_loss/len(trainloader)\n",
    "        valid_accuracy, valid_loss,valid_count=test(validloader,model,criterion,device)\n",
    "        print (datetime.datetime.now())\n",
    "        print(f\"Epoch {epoch+1}/{epochs}.. \"\n",
    "              f\"Train loss: {train_loss:.3f}.. \"\n",
    "              f\"Valid loss: {valid_loss:.3f}.. \"\n",
    "              f\"Valid accuracy: {valid_accuracy:.5f}..\"\n",
    "              f\"Time Elspased so far: {time.time()-start:.3f} seconds\")\n",
    "        train_loss = 0\n",
    "        train_accuracy=0\n",
    "        if valid_count>valid_count_max:\n",
    "            print(f\"*************New Model Saved with correct predictions of:{valid_count:.5f}***************\")\n",
    "            torch.save(model, model_path_name)\n",
    "            valid_count_max= valid_count\n",
    "    return model,valid_count_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model instainstiation\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "if(retrain):\n",
    "    model = torch.load(model_path)\n",
    "else:\n",
    "    model=eval(\"models.\"+selected_net+\"(pretrained=net_pretrained)\")\n",
    "    torch.save(model, model_path_name)\n",
    "    if(not full_train):\n",
    "        for par in  model.parameters():\n",
    "            param.requires_grad=False\n",
    "    #change FC classifier\n",
    "    model.fc = nn.Sequential(nn.Linear(FC[net_index], 1024),\n",
    "                                     nn.ReLU(),\n",
    "                                     nn.Linear(1024, 256),\n",
    "                                     nn.ReLU(),\n",
    "                                     #nn.Dropout(0.2), #optional\n",
    "                                     nn.Linear(256, output_classes),\n",
    "                                     nn.LogSoftmax(dim=1)) \n",
    "    \n",
    "\n",
    "criterion = nn.NLLLoss()\n",
    "\n",
    "# Only train the classifier parameters, feature parameters are frozen\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "model.to(device);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test model intially over validation set\n",
    "valid_acc_max,valid_loss,valid_count_max=test(validloader,model,criterion,device)\n",
    "#valid_acc_max=valid_accuracy/len(validloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_acc_max,valid_loss,valid_count_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train model\n",
    "epochs=3\n",
    "model,valid_count_max = train(epochs, trainloader,validloader, model, optimizer,criterion,device,model_path,valid_count_max) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test model\n",
    "\n",
    "test_accuracy,test_loss,test_count=test(testloader,model,criterion,device)\n",
    "print(f\"Test loss: {test_loss:.3f}.. \"\n",
    "    f\"Test accuracy: {test_accuracy:.5f}..\"\n",
    "    f\"Test count: {test_count:.5f}.. \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader_dic={\"train\":trainloader,\"valid\":validloader,\"test\":testloader}\n",
    "#loader_dic={\"valid\":validloader,\"test\":testloader}\n",
    "for i in loader_dic:\n",
    "    loader=loader_dic[i]\n",
    "    print(i+\" data set\")\n",
    "    test_report(model,loader,device)\n",
    "    print(\"*\"*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in net_dic.keys():\n",
    "    model=eval(\"models.\"+net_dic[i]+\"(pretrained=net_pretrained)\")\n",
    "    print(\"*\"*60)\n",
    "    print(net_dic[i])\n",
    "    print(\"*\"*60)\n",
    "    print (model)\n",
    "    print(\"*\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FC=[9216,25088,25088,25088,25088,25088,25088,25088,25088,512,512,2048,2048,2048,1024,1664,1920,2208,2048]\n",
    "len(FC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
